{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73941507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wbddh\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from rio_tiler.io import COGReader\n",
    "from rio_tiler.utils import create_cutline\n",
    "from rasterio.features import bounds as featureBounds\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f32fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you don't have the package installed, you can install it using pip\n",
    "\n",
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac8294",
   "metadata": {},
   "source": [
    "## Introduction to Data Catalog (DDH) APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09b9e3",
   "metadata": {},
   "source": [
    "The Data Catalog (DDH) is the World Bank’s central data hub, hosting more than 16,000 datasets—including indicators, microdata, geospatial assets, and reproducibility packages. DDH underpins many Bank platforms by offering direct, cloud-native access to data that applications can consume seamlessly.\n",
    "\n",
    "For this session we want to showcase some of the commonly used API endpoints that can help you in identifying what data you need and how to use them in your workflows. \n",
    "\n",
    "DDH serves both intenral and external audience, so you'll notice separate api hosts for them. The internal host requires user authentication, and additional documentation will be provided to guide you through the process. \n",
    "\n",
    "We've developed a [swagger page](https://ddh-openapi.worldbank.org/docs/index.html) that provides more information on all the DDH endpoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e9076",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ce6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://ddh-openapi.worldbank.org -- host for external use\n",
    "\n",
    "## Setting the API host to the internal one. If you are an external user, please set it to the external one.\n",
    "\n",
    "wbddh.set_api_host(\"https://ddh-openapi.worldbank.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43be8d",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418cd99",
   "metadata": {},
   "source": [
    "You can search entire data catalog by either passing keywords (as you would on the UI), or by applying filters to different fields. DDH has it own metadata schema, so be sure take a look a dataset response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of all datasets in DDH\n",
    "## Requires pagination. Default is set to 50 records\n",
    "\n",
    "ds_all = wbddh.get(\"datasets\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f080ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This view provides basic information about the datasets, including the dataset unique ID, name, description, and related dates.\n",
    "\n",
    "pd.DataFrame(ds_all['data']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search by keyword\n",
    "\n",
    "params = {\"qname\" :  \"dataset\",\n",
    "          \"param\" : \"gdp\"}\n",
    "\n",
    "ds_gdp = wbddh.get(\"search\", params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_gdp['data']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search by filtering by country\n",
    "\n",
    "params = {\"qname\": \"dataset\",\n",
    "          \"filter\" : \"geographical_extent/coverage/any(i: i/code eq 'AF')\"}\n",
    "\n",
    "ds_con = wbddh.get(\"search\", params = params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2010677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_con['data']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search for a dataset by its unique identifier\n",
    "\n",
    "## 0066940 - Space2Stats Monthly & Annual Black Marble Nighttime Lights\n",
    "\n",
    "ds = wbddh.get(f\"datasets/0066940\", params= {\"show_resources\" : True}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0500b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check resources for the dataset\n",
    "\n",
    "for resource in ds['resources']:\n",
    "    print(resource['name'], ':', resource['resource_unique_id'], '\\n File Format -', resource['format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb12339",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting data schema for a resource\n",
    "\n",
    "wbddh.get(f\"resources/DR0095688/metadata\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa394a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting data for a resource\n",
    "## You can use the filter parameter to filter the data. The syntax for the filter parameter is based on OData filter syntax.\n",
    "\n",
    "rs_params = {\n",
    "    'filter' : \"ISO_A3='IND'\"\n",
    "     \n",
    "}\n",
    "rs = wbddh.get(f\"resources/DR0095688/data\", params=rs_params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rs['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc31247",
   "metadata": {},
   "source": [
    "### Accessing geospatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3d092",
   "metadata": {},
   "source": [
    "While the endpoint above provides access to tabular data, the following snippets will showcase how to retrieve geospatial data directly from DDH storage. \n",
    "\n",
    "P.S. The full suite of geospatial services will be made available later this year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ad84a",
   "metadata": {},
   "source": [
    "#### Vector Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79686477",
   "metadata": {},
   "source": [
    "Some vector data formats such as CSV, Geojson, Geoparquet, Gpkg can be read directly the storage. Here we'll use a dataset with a Geojson resource.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6238a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read a Power Plant dataset from Uzbekistan\n",
    "\n",
    "ds = wbddh.get(f\"datasets/0041474\", params= {\"show_resources\" : True}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca07608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for resource in ds['resources']:\n",
    "    print(resource['name'], ':', resource['resource_unique_id'], '\\n', resource['url'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7933545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in Existing Power Plants in Uzbekistan dataset\n",
    "\n",
    "uz_pp = gpd.read_file(ds['resources'][0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da88a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the power plants in Uzbekistan\n",
    "uz_pp.explore().save(\"uz_pp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If gdf.explore fails, you can also use leafmap to visualize the data \n",
    "\n",
    "# !pip install leafmap \n",
    "# import leafmap\n",
    "\n",
    "# m = leafmap.Map()\n",
    "# m.add_gdf(uz_pp, layer_name=\"My Points\")\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3899a",
   "metadata": {},
   "source": [
    "#### Raster Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac11089",
   "metadata": {},
   "source": [
    "Some datasets on DDH have been made Cloud Optimized Geotiff (COG) compatible, so you can query the data for your AOI instead of downloading the entire file on your computer. In this example, we have a Maize mask for Malawi, and we'll subset it to a small region for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geojson for a polygon\n",
    "## Malawi\n",
    "\n",
    "feat ={\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              33.64022163514227,\n",
    "              -13.095832877158898\n",
    "            ],\n",
    "            [\n",
    "              33.64022163514227,\n",
    "              -13.509532545665095\n",
    "            ],\n",
    "            [\n",
    "              34.134782313766124,\n",
    "              -13.509532545665095\n",
    "            ],\n",
    "            [\n",
    "              34.134782313766124,\n",
    "              -13.095832877158898\n",
    "            ],\n",
    "            [\n",
    "              33.64022163514227,\n",
    "              -13.095832877158898\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64422fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BBOX of the polygon\n",
    "bbox = featureBounds(feat)\n",
    "\n",
    "# Use COGReader to open and read the dataset\n",
    "with COGReader(\"https://datacatalogfiles.worldbank.org/ddh-published/0037935/1/DR0046011/mwi_maize_mask_cog_2016.tif\") as cog:\n",
    "    # Create WTT Cutline\n",
    "    cutline = create_cutline(cog.dataset, feat, geometry_crs=\"epsg:4326\")\n",
    "\n",
    "    # Read part of the data (bbox) and use the cutline to mask the data\n",
    "    data_, mask_ = cog.part(bbox, vrt_options={'cutline': cutline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viasualize the masked data\n",
    "\n",
    "plt.imshow(data_[0,:,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc1d6f",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc7f85",
   "metadata": {},
   "source": [
    "- Search for \"Burkina Faso Administrative Boundaries\" dataset on DDH and retrieve metadata for all its resources. \n",
    "- Use the resource IDs to get the file URL for \"District boundary\" geojson file. \n",
    "- Now search for \"Burkina Faso - Electricity Transmission Network\" dataset and get the fle link for Geojson file. \n",
    "- Use these two layers to visually overlay on top of each other\n",
    "\n",
    "Hint:\n",
    "- While plotting first geodataframe, assign it to a variable `ax`\n",
    "- For second dataframe's plot, assign the parameter `ax=ax`. For instance, plot for gdf2 will look like `gdf2.plot(ax=ax)`\n",
    "- Double check if the two geodataframes have the same CRS. \n",
    "    - check if `print(gdf1.crs == gdf2.crs)`\n",
    "    - If not, you can set gdf2 crs as `gdf2 = gdf2.set_crs(gdf1.crs, allow_override=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235203c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61782f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0345b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2a82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
